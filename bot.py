# bot.py ‚Äî Nature Inspire (—Ñ–∏–∫—Å –º–∏–∫—Å–∞): HDR-only = Nature Enhance 2.0, WOW = —Å–æ—á–Ω—ã–π —Ç–æ–ø-–ø–∞–π–ø–ª–∞–π–Ω
# + üéª Violin Touch (—Ç–≤–æ–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã) + –º—è–≥–∫–∏–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π Clarity –¥–ª—è WOW –∏ Violin ¬´–£—Å–∏–ª–µ–Ω–∏–µ¬ª
# env: TELEGRAM_API_TOKEN, REPLICATE_API_TOKEN (–æ–ø—Ü., –¥–ª—è Clarity)

import os, logging, tempfile, urllib.request, traceback
import numpy as np
from PIL import Image, ImageFilter, ImageOps, ImageEnhance, ImageChops
from aiogram import Bot, Dispatcher, types
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton, InputFile
from aiogram.utils import executor

# --- –æ–ø—Ü. –¥–ª—è Clarity ---
try:
    import replicate
except Exception:
    replicate = None

logging.basicConfig(level=logging.INFO)

# ---------- TOKENS ----------
API_TOKEN  = os.getenv("TELEGRAM_API_TOKEN")
if not API_TOKEN:  raise RuntimeError("TELEGRAM_API_TOKEN missing")
REPL_TOKEN = os.getenv("REPLICATE_API_TOKEN")  # –º–æ–∂–µ—Ç –±—ã—Ç—å None
if REPL_TOKEN and replicate:
    os.environ["REPLICATE_API_TOKEN"] = REPL_TOKEN

bot = Bot(token=API_TOKEN)
dp  = Dispatcher(bot)

# ---------- TUNABLES ----------
INPUT_MAX_SIDE       = 1536
FINAL_TELEGRAM_LIMIT = 10 * 1024 * 1024

# UI —É—Ä–æ–≤–Ω–∏ (–º—è–≥–∫–∏–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç; —Å–∞–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫—Ä—É—Ç—è—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –Ω–∏–∂–µ)
UI_LOW, UI_MED, UI_HIGH = 0.01, 0.50, 1.00

# ==== WOW: –†–ê–ó–î–ï–õ–¨–ù–´–ï –ö–†–£–¢–ò–õ–ö–ò ==================================================
# 1) COLOR ‚Äî –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å/–≤–∏–±—Ä–∞–Ω—Å (–¥–µ–ª–∏–∫–∞—Ç–Ω–æ –ø–æ–¥–Ω–∏–º–∞–µ—Ç ¬´–ø–ª–æ—Å–∫–∏–µ¬ª —Ü–≤–µ—Ç–∞)
COLOR_VIBRANCE_BASE   = 0.42
COLOR_CONTRAST_BASE   = 0.15
COLOR_BRIGHT_BASE     = 0.02

# 2) DEPTH ‚Äî ¬´–æ–±—ä—ë–º¬ª: S-–∫—Ä–∏–≤–∞—è, –º–∏–∫—Ä–æ–∫–æ–Ω—Ç—Ä–∞—Å—Ç (high-pass), —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —à–∞—Ä–ø
DEPTH_S_CURVE_BASE    = 0.35
DEPTH_MICROCONTR_BASE = 0.2
DEPTH_HP_RADIUS_BASE  = 1.40
DEPTH_UNSHARP_BASE    = 130

# 3) DRAMA ‚Äî –¥—Ä–∞–º–∞—Ç–∏–∑–º: HDR-–∫—Ä–∏–≤–∞—è (–ª–æ–≥), bloom —Ö–∞–π–ª–∞–π—Ç–æ–≤
DRAMA_HDR_LOGA_BASE   = 3
DRAMA_BLOOM_AMOUNT    = 0.9
DRAMA_BLOOM_RADIUS    = 2.00

# –ê–Ω—Ç–∏-—Å–µ—Ä–æ—Å—Ç—å (–≥–∞—Ä–∞–Ω—Ç–∏—è, —á—Ç–æ –Ω–µ –ø–æ—Ç–µ–º–Ω–µ–µ—Ç)
ANTI_GREY_TOL = 0.98
ANTI_GREY_CAP = 1.35

# --- Clarity (Replicate) ---
MODEL_CLARITY = "philz1337x/clarity-upscaler:dfad41707589d68ecdccd1dfa600d55a208f9310748e44bfe35b4a6291453d5e"
CL_SCALE_FACTOR      = 2           # –∞–ø—Å–∫–µ–π–ª √ó2 (–º—è–≥–∫–æ)
CL_DYNAMIC           = 6.0
CL_CREATIVITY        = 0.20
CL_RESEMBLANCE       = 0.70
CL_TILING_W, CL_TILING_H = 112, 144
CL_STEPS             = 18
CL_SD_MODEL          = "juggernaut_reborn.safetensors [338b85bc4f]"
CL_SCHEDULER         = "DPM++ 3M SDE Karras"
CL_NEGATIVE          = "(worst quality, low quality, normal quality:2) JuggernautNegative-neg"
CL_LORA_MORE_DETAILS = 0.5
CL_LORA_RENDER       = 1.0
# ================================================================================

# ---------- STATE ----------
# user_id -> {'effect': 'ne2' | 'wow_menu' | 'wow' | 'violin_menu' | 'violin' | 'violin_boost', 'ui_gain': float}
WAIT = {}

# ---------- HELPERS ----------
def resize_inplace(path: str, max_side: int):
    try:
        im = Image.open(path)
        im = ImageOps.exif_transpose(im).convert("RGB")
        if max(im.size) > max_side:
            im.thumbnail((max_side, max_side), Image.LANCZOS)
        im.save(path, "JPEG", quality=95, optimize=True)
    except Exception:
        pass

def ensure_size_under_telegram_limit(path: str, max_bytes: int = FINAL_TELEGRAM_LIMIT) -> str:
    try:
        if os.path.getsize(path) <= max_bytes: return path
        img = Image.open(path).convert("RGB")
        q = 92
        for _ in range(10):
            fd, tmp = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
            img.save(tmp, "JPEG", quality=q, optimize=True)
            if os.path.getsize(tmp) <= max_bytes:
                os.remove(path); return tmp
            os.remove(tmp); q -= 8
        fd, tmp = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
        img.save(tmp, "JPEG", quality=max(q, 40), optimize=True)
        os.remove(path); return tmp
    except Exception:
        return path

def tg_url(file_path: str) -> str:
    return f"https://api.telegram.org/file/bot{API_TOKEN}/{file_path}"

async def download_tg_photo(file_id: str) -> str:
    tg_file = await bot.get_file(file_id)
    url = tg_url(tg_file.file_path)
    fd, path = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
    urllib.request.urlretrieve(url, path)
    resize_inplace(path, INPUT_MAX_SIDE)
    return path

def download_to_temp(url: str, suffix=".jpg") -> str:
    fd, path = tempfile.mkstemp(suffix=suffix); os.close(fd)
    urllib.request.urlretrieve(url, path)
    return path

def _pick_first_url(x):
    try:
        if isinstance(x, str): return x
        if isinstance(x, (list, tuple)) and x:
            o0 = x[0]; u = getattr(o0, "url", None)
            return u() if callable(u) else (u or str(o0))
        u = getattr(x, "url", None)
        return u() if callable(u) else (u or str(x))
    except:
        return str(x)

# ---------- CORE OPS ----------
def _vibrance(arr: np.ndarray, gain: float) -> np.ndarray:
    mx = arr.max(axis=-1, keepdims=True)
    mn = arr.min(axis=-1, keepdims=True)
    sat = mx - mn
    w   = 1.0 - sat          # –±–æ–ª—å—à–µ –±—É—Å—Ç —Ç–∞–º, –≥–¥–µ –º–∞–ª–æ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏
    mean = arr.mean(axis=-1, keepdims=True)
    out  = mean + (arr - mean) * (1.0 + gain * w)
    return np.clip(out, 0.0, 1.0)

def _s_curve(x: np.ndarray, amt: float) -> np.ndarray:
    return np.clip(x*(1-amt) + (3*x*x - 2*x*x*x)*amt, 0.0, 1.0)

# ---------- EFFECTS ----------
def hdr_only_path(orig_path: str) -> str:
    """–ù–∞—Ç—É—Ä–∞–ª—å–Ω—ã–π HDR-only –¥–ª—è Nature Enhance 2.0 (–±–µ–∑ —Å–µ—Ä–æ—Å—Ç–∏)."""
    im = Image.open(orig_path).convert("RGB")
    im = ImageOps.exif_transpose(im)
    a = 3.0
    arr = np.asarray(im).astype(np.float32)/255.0
    luma = 0.2627*arr[...,0] + 0.6780*arr[...,1] + 0.0593*arr[...,2]
    y    = np.log1p(a*luma) / (np.log1p(a)+1e-8)
    ratio = y / np.maximum(luma, 1e-6)
    arr = np.clip(arr * ratio[...,None], 0.0, 1.0)

    out = Image.fromarray((arr*255).astype(np.uint8))
    out = ImageEnhance.Brightness(out).enhance(1.00)
    out = ImageEnhance.Contrast(out).enhance(1.06)

    fd, path = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
    out.save(path, "JPEG", quality=95, optimize=True)
    return path

def wow_enhance_path(orig_path: str, ui_gain: float) -> str:
    """
    WOW-–ø–∞–π–ø–ª–∞–π–Ω: —Å–æ—á–Ω—ã–π —Ç–æ–ø.
    ui_gain ‚Äî –º—è–≥–∫–∏–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –∫–Ω–æ–ø–∫–∏ (0.1 / 0.50 / 1.00).
    """
    g = float(ui_gain)

    base = Image.open(orig_path).convert("RGB")
    base = ImageOps.exif_transpose(base)
    arr  = np.asarray(base).astype(np.float32)/255.0

    # —è—Ä–∫–æ—Å—Ç—å –¥–ª—è –∞–Ω—Ç–∏-—Å–µ—Ä–æ—Å—Ç–∏
    in_luma = 0.2627*arr[...,0] + 0.6780*arr[...,1] + 0.0593*arr[...,2]
    in_mean = float(in_luma.mean())

    # DRAMA: HDR (–ª–æ–≥ –ø–æ –ª—É–º–µ)
    A = DRAMA_HDR_LOGA_BASE * g
    y = np.log1p(A*in_luma) / (np.log1p(A)+1e-8)
    ratio = y / np.maximum(in_luma, 1e-6)
    arr = np.clip(arr * ratio[...,None], 0.0, 1.0)

    # DEPTH: S-curve
    arr = _s_curve(arr, amt= DEPTH_S_CURVE_BASE * g)

    # COLOR: Vibrance
    arr = _vibrance(arr, gain= COLOR_VIBRANCE_BASE * g)

    # COLOR –≥–ª–æ–±–∞–ª—å–Ω—ã–µ
    im = Image.fromarray((arr*255).astype(np.uint8))
    im = ImageEnhance.Contrast(im).enhance(1.0 + COLOR_CONTRAST_BASE * g)
    im = ImageEnhance.Brightness(im).enhance(1.0 + COLOR_BRIGHT_BASE  * g)

    # DEPTH: Microcontrast (high-pass)
    hp_r = DEPTH_HP_RADIUS_BASE * g
    blurred = im.filter(ImageFilter.GaussianBlur(radius=hp_r))
    hp = ImageChops.subtract(im, blurred)
    hp = hp.filter(ImageFilter.UnsharpMask(radius=1.0, percent=int(90 + 110*g), threshold=3))
    im = Image.blend(im, hp, min(0.6, DEPTH_MICROCONTR_BASE * g))

    # DRAMA: Bloom —Ö–∞–π–ª–∞–π—Ç–æ–≤
    if DRAMA_BLOOM_AMOUNT > 0:
        glow = im.filter(ImageFilter.GaussianBlur(radius=DRAMA_BLOOM_RADIUS + 4.0*g))
        im = Image.blend(im, ImageChops.screen(im, glow), DRAMA_BLOOM_AMOUNT * g)

    # DEPTH: —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–∏–∫—Ä–æ—à–∞—Ä–ø
    im = im.filter(ImageFilter.UnsharpMask(radius=1.0, percent=int(DEPTH_UNSHARP_BASE * g), threshold=2))

    # –∞–Ω—Ç–∏-—Å–µ—Ä–æ—Å—Ç—å
    out_mean = np.asarray(im.convert("L")).astype(np.float32).mean()/255.0
    if out_mean < in_mean * ANTI_GREY_TOL:
        gain = min(ANTI_GREY_CAP, max(1.00, (in_mean / max(out_mean, 1e-6)) ** 0.85))
        im = ImageEnhance.Brightness(im).enhance(gain)

    fd, path = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
    im.save(path, "JPEG", quality=95, optimize=True)
    return path

def violin_touch_path(orig_path: str) -> str:
    """
    üéª Violin Touch ‚Äî ¬´–º—É–∑—ã–∫–∞–ª—å–Ω—ã–π¬ª —Ü–≤–µ—Ç/–æ–±—ä—ë–º (—á—É—Ç—å —Ç–µ–º–Ω–µ–µ –∏ —Å–æ—á–Ω–µ–µ).
    –ë–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π; —Ç–æ–ª—å–∫–æ PIL/NumPy.
    >>> –í–ê–ñ–ù–û: –∑–Ω–∞—á–µ–Ω–∏—è –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –∫–∞–∫ —Ç—ã –Ω–∞—Å—Ç—Ä–æ–∏–ª.
    """
    base = Image.open(orig_path).convert("RGB")
    base = ImageOps.exif_transpose(base)
    arr  = np.asarray(base).astype(np.float32)/255.0

    # 1) HDR-–ª–æ–≥ –º—è–≥—á–µ (—á—Ç–æ–±—ã –Ω–µ –≤—ã—Å–≤–µ—Ç–ª—è—Ç—å)
    l = 0.2627*arr[...,0] + 0.6780*arr[...,1] + 0.0593*arr[...,2]
    A = 2.7
    y = np.log1p(A*l) / (np.log1p(A)+1e-8)
    arr = np.clip(arr * (y/np.maximum(l,1e-6))[...,None], 0, 1)

    # 2) –ü–ª—ë–Ω–æ—á–Ω–∞—è S-–∫—Ä–∏–≤–∞—è (—á—É—Ç—å —Å–∏–ª—å–Ω–µ–µ –¥–ª—è –æ–±—ä—ë–º–∞)
    arr = _s_curve(arr, amt=0.24)

    # 3) Vibrance —Å –∑–∞—â–∏—Ç–æ–π –∫–æ–∂–∏
    im_hsv = Image.fromarray((arr*255).astype(np.uint8)).convert("HSV")
    hsv    = np.asarray(im_hsv).astype(np.float32)
    H,S,V  = hsv[...,0], hsv[...,1], hsv[...,2]
    skin = (((H>=15) & (H<=35)) & (S>20) & (V>40)).astype(np.float32)

    def _vib(a, gain):
        mx = a.max(axis=-1, keepdims=True); mn = a.min(axis=-1, keepdims=True)
        sat = mx - mn; w = 1.0 - sat; mean = a.mean(axis=-1, keepdims=True)
        return np.clip(mean + (a-mean)*(1.0 + gain*w), 0.0, 1.0)

    vib_gain = 0.48
    vib = _vib(arr, vib_gain)
    arr = np.clip(arr*(skin[...,None]) + vib*(1.0-skin[...,None]), 0, 1)

    im = Image.fromarray((arr*255).astype(np.uint8))

    # 4) –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç + –ª—ë–≥–∫–∏–π bloom
    hp = ImageChops.subtract(im, im.filter(ImageFilter.GaussianBlur(radius=1.2)))
    im = Image.blend(im, hp, 0.32)
    glow = im.filter(ImageFilter.GaussianBlur(radius=2.0))
    im = Image.blend(im, ImageChops.screen(im, glow), 0.04)

    # 5) –û–±—â–∏–µ –ø—Ä–∞–≤–∫–∏: —Ü–≤–µ—Ç/–∫–æ–Ω—Ç—Ä–∞—Å—Ç, –±–µ–∑ –æ—Å–≤–µ—Ç–ª–µ–Ω–∏—è
    im = ImageEnhance.Color(im).enhance(1.08)
    im = ImageEnhance.Contrast(im).enhance(1.14)
    im = ImageEnhance.Brightness(im).enhance(1.00)
    im = im.filter(ImageFilter.UnsharpMask(radius=1.0, percent=120, threshold=2))

    fd, path = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
    im.save(path, "JPEG", quality=95, optimize=True)
    return path

# ---------- CLARITY (–º—è–≥–∫–∏–π –ø–æ—Å—Ç-–ø—Ä–æ—Ö–æ–¥) ----------
def clarity_post_path(local_path: str) -> str:
    """–ù–µ–∂–Ω—ã–π Clarity –∫–∞–∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —à—Ç—Ä–∏—Ö. –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω–∞/—Ä–µ–ø–ª–∏–∫–µ–π—Ç–∞ –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω—ë–º –∏—Å—Ö–æ–¥–Ω–∏–∫."""
    if not (REPL_TOKEN and replicate):
        return local_path
    try:
        with open(local_path, "rb") as f:
            out = replicate.run(MODEL_CLARITY, input={
                "image": f,
                "prompt": "<lora:more_details:%s>\n<lora:SDXLrender_v2.0:%s>" % (CL_LORA_MORE_DETAILS, CL_LORA_RENDER),
                "negative_prompt": CL_NEGATIVE,
                "scale_factor": CL_SCALE_FACTOR,
                "dynamic": CL_DYNAMIC,
                "creativity": CL_CREATIVITY,
                "resemblance": CL_RESEMBLANCE,
                "tiling_width": CL_TILING_W,
                "tiling_height": CL_TILING_H,
                "sd_model": CL_SD_MODEL,
                "scheduler": CL_SCHEDULER,
                "num_inference_steps": CL_STEPS,
                "downscaling": False,
                "sharpen": 0,
                "handfix": "disabled",
                "output_format": "png",
                "seed": 1337
            })
        url = _pick_first_url(out)
        if not url:  # –ø–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
            return local_path
        new_path = download_to_temp(url, ".png")
        # –∫–æ–Ω–≤–µ—Ä—Ç –≤ jpg (–¥–ª—è –≤–µ—Å–∞)
        im = Image.open(new_path).convert("RGB")
        fd, jpg = tempfile.mkstemp(suffix=".jpg"); os.close(fd)
        im.save(jpg, "JPEG", quality=95, optimize=True)
        try:
            os.remove(new_path)
        except: pass
        return jpg
    except Exception:
        return local_path

# ---------- UI ----------
KB_MAIN = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton("üåø Nature Enhance 2.0 (HDR)")],
        [KeyboardButton("üåø WOW Enhance (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)")],
        [KeyboardButton("üéª Violin Touch")],
    ],
    resize_keyboard=True
)
KB_STRENGTH = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥")],
        [KeyboardButton("–ù–∏–∑–∫–∞—è"), KeyboardButton("–°—Ä–µ–¥–Ω—è—è"), KeyboardButton("–í—ã—Å–æ–∫–∞—è")],
    ], resize_keyboard=True
)
KB_VIOLIN = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥")],
        [KeyboardButton("–û–±—ã—á–Ω—ã–π üéª"), KeyboardButton("–£—Å–∏–ª–µ–Ω–∏–µ üéª")],
    ], resize_keyboard=True
)

@dp.message_handler(commands=["start"])
async def on_start(m: types.Message):
    await m.answer(
        "Nature Inspire üåø\n"
        "‚Ä¢ Nature Enhance 2.0 ‚Äî HDR-only (–º—è–≥–∫–∏–π, –±–µ–∑ —Å–µ—Ä–æ—Å—Ç–∏)\n"
        "‚Ä¢ WOW Enhance ‚Äî —Å–æ—á–Ω—ã–π —Ç–æ–ø-–ø–∞–π–ø–ª–∞–π–Ω (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)\n"
        "‚Ä¢ üéª Violin Touch ‚Äî –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ü–≤–µ—Ç/–æ–±—ä—ë–º (–≥–ª—É–±–æ–∫–∏–µ —Å–∏–Ω–∏–µ)\n"
        "–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º.",
        reply_markup=KB_MAIN
    )

@dp.message_handler(lambda m: m.text in ["üåø Nature Enhance 2.0 (HDR)", "üåø WOW Enhance (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)", "üéª Violin Touch", "–û–±—ã—á–Ω—ã–π üéª", "–£—Å–∏–ª–µ–Ω–∏–µ üéª"])
async def on_mode(m: types.Message):
    uid = m.from_user.id
    txt = m.text
    if txt == "üåø WOW Enhance (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)":
        WAIT[uid] = {"effect": "wow_menu"}
        await m.answer("–í—ã–±–µ—Ä–∏ —Å–∏–ª—É —ç—Ñ—Ñ–µ–∫—Ç–∞:", reply_markup=KB_STRENGTH)
    elif txt == "üéª Violin Touch":
        WAIT[uid] = {"effect": "violin_menu"}
        await m.answer("–í—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç üéª:", reply_markup=KB_VIOLIN)
    elif txt == "–û–±—ã—á–Ω—ã–π üéª":
        WAIT[uid] = {"effect": "violin"}
        await m.answer("–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ ‚Äî —Å–¥–µ–ª–∞—é üéª Violin Touch", reply_markup=KB_MAIN)
    elif txt == "–£—Å–∏–ª–µ–Ω–∏–µ üéª":
        WAIT[uid] = {"effect": "violin_boost"}
        await m.answer("–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ ‚Äî —Å–¥–µ–ª–∞—é üéª Violin Touch (—É—Å–∏–ª–µ–Ω–∏–µ)", reply_markup=KB_MAIN)
    else:
        WAIT[uid] = {"effect": "ne2"}
        await m.answer("–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ ‚Äî —Å–¥–µ–ª–∞—é Nature Enhance 2.0 üåø", reply_markup=KB_MAIN)

@dp.message_handler(lambda m: m.text in ["–ù–∏–∑–∫–∞—è","–°—Ä–µ–¥–Ω—è—è","–í—ã—Å–æ–∫–∞—è","‚¨ÖÔ∏è –ù–∞–∑–∞–¥"])
async def on_strength(m: types.Message):
    uid = m.from_user.id
    st  = WAIT.get(uid)
    if not st: return
    if m.text == "‚¨ÖÔ∏è –ù–∞–∑–∞–¥":
        WAIT.pop(uid, None); await m.answer("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é.", reply_markup=KB_MAIN); return
    if st.get("effect") != "wow_menu":  # ¬´–ù–∞–∑–∞–¥¬ª –∏–∑ –¥—Ä—É–≥–∏—Ö –º–µ–Ω—é —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏
        return
    ui_gain = UI_MED
    if m.text == "–ù–∏–∑–∫–∞—è":  ui_gain = UI_LOW
    if m.text == "–í—ã—Å–æ–∫–∞—è": ui_gain = UI_HIGH
    WAIT[uid] = {"effect": "wow", "ui_gain": float(ui_gain)}
    await m.answer("–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ ‚Äî —Å–¥–µ–ª–∞—é WOW Enhance üåø", reply_markup=KB_MAIN)

@dp.message_handler(content_types=["photo"])
async def on_photo(m: types.Message):
    uid = m.from_user.id
    st  = WAIT.get(uid)
    if not st or st.get("effect") not in ["ne2", "wow", "violin", "violin_boost"]:
        await m.reply("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º ‚¨áÔ∏è", reply_markup=KB_MAIN); return

    await m.reply("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")
    try:
        local = await download_tg_photo(m.photo[-1].file_id)

        eff = st["effect"]
        if eff == "ne2":
            out = hdr_only_path(local)

        elif eff == "violin":
            out = violin_touch_path(local)

        elif eff == "violin_boost":
            tmp = violin_touch_path(local)
            out = clarity_post_path(tmp)  # –º—è–≥–∫–∏–π clarity-—à—Ç—Ä–∏—Ö
            try:
                if tmp != out and os.path.exists(tmp): os.remove(tmp)
            except: pass

        else:  # wow
            tmp = wow_enhance_path(local, ui_gain=float(st.get("ui_gain", UI_MED)))
            out = clarity_post_path(tmp)  # –º—è–≥–∫–∏–π clarity-—à—Ç—Ä–∏—Ö
            try:
                if tmp != out and os.path.exists(tmp): os.remove(tmp)
            except: pass

        safe = ensure_size_under_telegram_limit(out)
        await m.reply_photo(InputFile(safe))
        try:
            for p in [local, out]:
                if os.path.exists(p): os.remove(p)
            if safe != out and os.path.exists(safe): os.remove(safe)
        except: pass
    except Exception:
        tb = traceback.format_exc(limit=20)
        await m.reply(f"üî• –û—à–∏–±–∫–∞ Nature Inspire:\n```\n{tb}\n```", parse_mode="Markdown")
    finally:
        WAIT.pop(uid, None)

if __name__ == "__main__":
    print(">> Starting polling‚Ä¶")
    executor.start_polling(dp, skip_updates=True)
